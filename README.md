# my-Back-Propagation
This code provides a simple but efficient approach for automatic back-propagation for any given computational graph of any topological structure. Compared with prevailing deep learning frameworks like Tensor Flow or PyTorch, it is short enough, easy enough, and flexible enough for beginners to get familiar with the principles of back-propagation and different network structures, including FC, Conv, ReLU, Softmax, Cross-Entropy Loss, Skip Connections for ResNet. It is implemented from scratch with python without importing any other libraries apart from numpy and queue.  
